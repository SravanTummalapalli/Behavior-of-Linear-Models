{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Tvnj5UblTy"
   },
   "source": [
    "## Task-D: Collinear features and their effect on linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qn_eOn2EblT3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMoYWIayblUB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfStXG4tblUI",
    "outputId": "ddf4eec6-7f53-4d28-914f-23133957d6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w  \\\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277   \n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364   \n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738   \n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720   \n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIIuomCkblUP"
   },
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1).values\n",
    "Y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3b5a83944a09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"correlation between features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m sns.heatmap(corr, cmap=\"BrBG\",\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mxticklabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         yticklabels=corr.columns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corr' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"correlation between features\")\n",
    "sns.heatmap(corr, cmap=\"BrBG\",\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydm98u3EblUU"
   },
   "source": [
    "### Doing perturbation test to check the presence of collinearity  \n",
    "\n",
    "#### Task: 1 Logistic Regression\n",
    "<pre>\n",
    "\n",
    "\n",
    "1. <b>Finding the Correlation between the features</b>\n",
    "    a. check the correlation between the features\n",
    "    b. plot heat map of correlation matrix using seaborn heatmap\n",
    "2. <b>Finding the best model for the given data</b>\n",
    "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
    "    random search CV make sure you choose the alpha in log space)\n",
    "    c. Creat a new Logistic regression with the best alpha\n",
    "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "    \n",
    "3. <b>Getting the weights with the original data</b>\n",
    "    a. train the 'best_model' with X, Y\n",
    "    b. Check the accuracy of the model 'best_model_accuracy'\n",
    "    c. Get the weights W using best_model.coef_\n",
    "\n",
    "4. <b>Modifying original data</b>\n",
    "    a. Add a noise(order of 10^-2) to each element of X \n",
    "    and get the new data set X' (X' = X + e)\n",
    "    b. Train the same 'best_model' with data (X', Y)\n",
    "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "    d. Get the weights W' using best_model.coef_\n",
    "    \n",
    "5. <b> Checking deviations in metric and weights </b>\n",
    "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "    c. print the top 4 features which have higher % change in weights \n",
    "    compare to the other feature\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Task: 2 Linear SVM\n",
    "\n",
    "<pre>\n",
    "1. Do the same steps (2, 3, 4, 5) we have done in the above task 1.\n",
    "</pre>\n",
    "\n",
    "<strong><font color='red'>Do write the observations based on the results you get from the deviations of weights in both Logistic Regression and linear SVM</font></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lai8wXU1pmSb"
   },
   "source": [
    "# 1. Find the coorelation between the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. check the correlation between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.812458</td>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.205926</td>\n",
       "      <td>0.996252</td>\n",
       "      <td>0.583277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>-0.401790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.812458</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.674486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x*x</th>\n",
       "      <td>0.997947</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.807137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>0.583803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*y</th>\n",
       "      <td>-0.205926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.602663</td>\n",
       "      <td>-0.209289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>-0.401790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <td>0.996252</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>0.847163</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.583277</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>0.583803</td>\n",
       "      <td>-0.401790</td>\n",
       "      <td>0.606860</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x         y         z       x*x       2*y  2*z+3*x*x  \\\n",
       "x          1.000000 -0.205926  0.812458  0.997947 -0.205926   0.996252   \n",
       "y         -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
       "z          0.812458 -0.602663  1.000000  0.807137 -0.602663   0.847163   \n",
       "x*x        0.997947 -0.209289  0.807137  1.000000 -0.209289   0.997457   \n",
       "2*y       -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
       "2*z+3*x*x  0.996252 -0.261123  0.847163  0.997457 -0.261123   1.000000   \n",
       "w          0.583277 -0.401790  0.674486  0.583803 -0.401790   0.606860   \n",
       "\n",
       "                  w  \n",
       "x          0.583277  \n",
       "y         -0.401790  \n",
       "z          0.674486  \n",
       "x*x        0.583803  \n",
       "2*y       -0.401790  \n",
       "2*z+3*x*x  0.606860  \n",
       "w          1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=data[data.columns[:-1]].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. plot heat map of correlation matrix using seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fb49140470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"correlation between features\")\n",
    "sns.heatmap(corr, cmap=\"BrBG\",\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding the best model for the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-05 2.78255940e-04 7.74263683e-03 2.15443469e-01\n",
      " 5.99484250e+00 1.66810054e+02 4.64158883e+03 1.29154967e+05\n",
      " 3.59381366e+06 1.00000000e+08]\n"
     ]
    }
   ],
   "source": [
    "alpha =  np.logspace(-5, 8, 10)\n",
    "print(alpha)\n",
    "param_grid={'C':alpha}\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-05, 2.78256e-04, 7.74264e-03, 2.15443e-01, 5.99484e+00,\n",
       "       1.66810e+02, 4.64159e+03, 1.29155e+05, 3.59381e+06, 1.00000e+08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Create a new Logistic regression with the best alpha\n",
    "    (search for how to get the best hyper parameter value), name the best model as 'best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1e-05}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting the weights with the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. train the 'best_model' with X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=LogisticRegression(C=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b. Check the accuracy of the model 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accu=accuracy_score(Y, predictions)\n",
    "print(accuracy_score(Y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Get the weights W using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00036369 -0.000345    0.00048449  0.00035933 -0.000345    0.00038189\n",
      "   0.00032048]]\n"
     ]
    }
   ],
   "source": [
    "wei=best_model.coef_[0]\n",
    "print(best_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modifying original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_NEW=X+.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Train the same 'best_model' with data (X', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model=best_model.fit(X_NEW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = best_model.predict(X_NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Check the accuracy of the model 'best_model_accuracy_edited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "new_accu=accuracy_score(Y, prediction)\n",
    "print(accuracy_score(Y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Get the weights W' using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00036369, -0.000345  ,  0.00048449,  0.00035933, -0.000345  ,\n",
       "         0.00038189,  0.00032048]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_new=updated_model.coef_\n",
    "w_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5.  Checking deviations in metric and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(new_accu-accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. find the absolute change between each value of W and W' ==> |(W-W')| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.04620171e-11 3.04801046e-11 3.04930581e-11 3.04600787e-11\n",
      " 3.04801046e-11 3.04634312e-11 3.04687841e-11]\n"
     ]
    }
   ],
   "source": [
    "difference=abs((wei-w_new))[0]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. print the top 4 features which have higher % change in weights compare to the other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(data.columns)-1\n",
    "percentage_change=[]\n",
    "for i in range (n):                   # calulating the percentage change in weight\n",
    "    cp=(difference[i]/wei[i])*100\n",
    "    percentage_change.append(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 4 features which have higher % change in weights \n",
      "2*z+3*x*x\n",
      "x\n",
      "x*x\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "columns=list(data.columns.values)\n",
    "indices=sorted(range(len(percentage_change)), key=lambda i: percentage_change[i])[-4:]\n",
    "print(\"the top 4 features which have higher % change in weights \")\n",
    "for j in indices:\n",
    "    print(columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: 2 Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding the best model for the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-05 2.78255940e-04 7.74263683e-03 2.15443469e-01\n",
      " 5.99484250e+00 1.66810054e+02 4.64158883e+03 1.29154967e+05\n",
      " 3.59381366e+06 1.00000000e+08]\n"
     ]
    }
   ],
   "source": [
    "alpha =  np.logspace(-5, 8, 10)\n",
    "print(alpha)\n",
    "param_grid={'C':alpha}\n",
    "svm = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or random search CV make sure you choose the alpha in log space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(svm, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-05, 2.78256e-04, 7.74264e-03, 2.15443e-01, 5.99484e+00,\n",
       "       1.66810e+02, 4.64159e+03, 1.29155e+05, 3.59381e+06, 1.00000e+08])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Create a new Logistic regression with the best alpha\n",
    "    (search for how to get the best hyper parameter value), name the best model as 'best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.007742636826811269}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting the weights with the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. train the 'best_model' with X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=SVC(kernel='linear',C=0.007742636826811269)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.007742636826811269, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b. Check the accuracy of the model 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X)\n",
    "accu=accuracy_score(Y, predictions)\n",
    "print(accuracy_score(Y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Get the weights W using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16056222 -0.20788705  0.32826166  0.14998082 -0.20788705  0.17461587\n",
      "   0.13401176]]\n"
     ]
    }
   ],
   "source": [
    "wei=best_model.coef_[0]\n",
    "print(best_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modifying original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Add a noise(order of 10^-2) to each element of X and get the new data set X' (X' = X + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_NEW=X+.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Train the same 'best_model' with data (X', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model=best_model.fit(X_NEW,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = best_model.predict(X_NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Check the accuracy of the model 'best_model_accuracy_edited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "new_accu=accuracy_score(Y, prediction)\n",
    "print(accuracy_score(Y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Get the weights W' using best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new=updated_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16049457, -0.20810298,  0.32832289,  0.14997999, -0.20810298,\n",
       "         0.17462251,  0.13395324]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_new#  5.  Checking deviations in metric and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5.  Checking deviations in metric and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(new_accu-accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. find the absolute change between each value of W and W' ==> |(W-W')| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.76507103e-05 2.15922620e-04 6.12315122e-05 8.28999945e-07\n",
      " 2.15922620e-04 6.64650571e-06 5.85197413e-05]\n"
     ]
    }
   ],
   "source": [
    "difference=abs((wei-w_new))[0]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. print the top 4 features which have higher % change in weights compare to the other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(data.columns)-1\n",
    "percentage_change=[]\n",
    "for i in range (n):                 \n",
    "    cp=(difference[i]/wei[i])*100\n",
    "    percentage_change.append(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 4 features which have higher % change in weights \n",
      "2*z+3*x*x\n",
      "z\n",
      "x\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "columns=list(data.columns.values)\n",
    "indices=sorted(range(len(percentage_change)), key=lambda i: percentage_change[i])[-4:]\n",
    "print(\"the top 4 features which have higher % change in weights \")\n",
    "for j in indices:\n",
    "    print(columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.In correlation matrix, some features are correlated.\n",
    "\n",
    "2.After implementing the perturbation on Support Vectro Machine and Logistic Regression,we observed the difference in weights are very minute.\n",
    "\n",
    "3.We can conclude that there is no collinearity between features based on pertubation test.\n",
    "\n",
    "4.From correlation matrix we can understand that top 4 features which are having higher percentage change in weights are higly correlated with other features."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "8D_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
